{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artificial_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctrivino1/Practicing-ML-algorithms-/blob/main/artificial_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5c92c4b0-dea9-4396-aee6-3a7937ae0c0e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "y = dataset[\"Exited\"]\n",
        "dataset.drop([\"Exited\", \"RowNumber\", \"CustomerId\", \"Surname\"], axis=1, inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a328b50-5ae4-4e92-9cc5-f1428f3ddf45"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
            "0             619    France  Female  ...          1               1        101348.88\n",
            "1             608     Spain  Female  ...          0               1        112542.58\n",
            "2             502    France  Female  ...          1               0        113931.57\n",
            "3             699    France  Female  ...          0               0         93826.63\n",
            "4             850     Spain  Female  ...          1               1         79084.10\n",
            "...           ...       ...     ...  ...        ...             ...              ...\n",
            "9995          771    France    Male  ...          1               0         96270.64\n",
            "9996          516    France    Male  ...          1               1        101699.77\n",
            "9997          709    France  Female  ...          0               1         42085.58\n",
            "9998          772   Germany    Male  ...          1               0         92888.52\n",
            "9999          792    France  Female  ...          1               0         38190.78\n",
            "\n",
            "[10000 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c610b5-0f32-4a0c-f30b-a534a3998344"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       1\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "9995    0\n",
            "9996    0\n",
            "9997    1\n",
            "9998    1\n",
            "9999    0\n",
            "Name: Exited, Length: 10000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "One hot encoding geogaphy and gender column / normalizing with minmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dataset = pd.get_dummies(dataset)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(dataset)\n",
        "\n",
        "X = pd.DataFrame(scaler.transform(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a62984-f2c9-46cb-aa13-23657401fe2a"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         0         1    2         3         4   ...   8    9    10   11   12\n",
            "0     0.538  0.324324  0.2  0.000000  0.000000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "1     0.516  0.310811  0.1  0.334031  0.000000  ...  0.0  0.0  1.0  1.0  0.0\n",
            "2     0.304  0.324324  0.8  0.636357  0.666667  ...  1.0  0.0  0.0  1.0  0.0\n",
            "3     0.698  0.283784  0.1  0.000000  0.333333  ...  1.0  0.0  0.0  1.0  0.0\n",
            "4     1.000  0.337838  0.2  0.500246  0.000000  ...  0.0  0.0  1.0  1.0  0.0\n",
            "...     ...       ...  ...       ...       ...  ...  ...  ...  ...  ...  ...\n",
            "9995  0.842  0.283784  0.5  0.000000  0.333333  ...  1.0  0.0  0.0  0.0  1.0\n",
            "9996  0.332  0.229730  1.0  0.228657  0.000000  ...  1.0  0.0  0.0  0.0  1.0\n",
            "9997  0.718  0.243243  0.7  0.000000  0.000000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "9998  0.844  0.324324  0.3  0.299226  0.333333  ...  0.0  1.0  0.0  0.0  1.0\n",
            "9999  0.884  0.135135  0.4  0.518708  0.000000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "\n",
            "[10000 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "# create a variable that will be an ANN, it will be a class\n",
        "\n",
        "ann = tf.keras.models.Sequential() # this creates and ANN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "# use dense class to build a connected layer\n",
        "# add allows me to add a layer\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))# units = # of nuerons I want in first layer\n",
        "# there is no magic number for how many nuerons I should have, I need to experiment\n",
        "# relu = rectifier activation function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "# same process as adding the layer above\n",
        "ann.add(tf.keras.layers.Dense(units=8,activation=\"relu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "# I have to change the values of my 2 parameters for output layer\n",
        "# since my outcome is only 1 or 0, I only need 1 unit back\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
        "# sigmoid is used for probabilities and I would like to know the prob of\n",
        "# the customer that may leave the bank\n",
        "# for classigiaction the activation must be softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "# Adam performs stochastic gradient descent\n",
        "# the optomizer will update the weights\n",
        "# binary_corssentropy is for binary classificatoin\n",
        "# for non binary(predicting three classes) classifcation use: categorical_crossentropy\n",
        "# I can choose different metricx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38acc58-e8b4-4f13-9740-54f4cb73becb"
      },
      "source": [
        "ann.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=.20)\n",
        "#fit method will train the model\n",
        "# batch_size default value is 32, means I am doign batch learning\n",
        "# epochs = # of times ANN is ran\n",
        "# is overfitting if training loss and accuracy are improving in their respective fields,\n",
        "# and val_loss and accuracy are decreasing in their respective fields"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8361 - val_loss: 0.4085 - val_accuracy: 0.8263\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8364 - val_loss: 0.4082 - val_accuracy: 0.8219\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8363 - val_loss: 0.4082 - val_accuracy: 0.8263\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8344 - val_loss: 0.4116 - val_accuracy: 0.8250\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8364 - val_loss: 0.4093 - val_accuracy: 0.8263\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8352 - val_loss: 0.4099 - val_accuracy: 0.8250\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8358 - val_loss: 0.4125 - val_accuracy: 0.8256\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8366 - val_loss: 0.4123 - val_accuracy: 0.8256\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8383 - val_loss: 0.4119 - val_accuracy: 0.8256\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8352 - val_loss: 0.4101 - val_accuracy: 0.8275\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8373 - val_loss: 0.4094 - val_accuracy: 0.8281\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8378 - val_loss: 0.4096 - val_accuracy: 0.8256\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8377 - val_loss: 0.4095 - val_accuracy: 0.8294\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8377 - val_loss: 0.4100 - val_accuracy: 0.8225\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8373 - val_loss: 0.4101 - val_accuracy: 0.8281\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8339 - val_loss: 0.4132 - val_accuracy: 0.8244\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8372 - val_loss: 0.4092 - val_accuracy: 0.8269\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8369 - val_loss: 0.4098 - val_accuracy: 0.8269\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8359 - val_loss: 0.4109 - val_accuracy: 0.8281\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8356 - val_loss: 0.4108 - val_accuracy: 0.8263\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8366 - val_loss: 0.4097 - val_accuracy: 0.8219\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8373 - val_loss: 0.4117 - val_accuracy: 0.8244\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8369 - val_loss: 0.4096 - val_accuracy: 0.8269\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8366 - val_loss: 0.4096 - val_accuracy: 0.8238\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8358 - val_loss: 0.4106 - val_accuracy: 0.8294\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8339 - val_loss: 0.4190 - val_accuracy: 0.8250\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8345 - val_loss: 0.4094 - val_accuracy: 0.8275\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8344 - val_loss: 0.4107 - val_accuracy: 0.8288\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8338 - val_loss: 0.4121 - val_accuracy: 0.8256\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8355 - val_loss: 0.4100 - val_accuracy: 0.8263\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8361 - val_loss: 0.4109 - val_accuracy: 0.8269\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8361 - val_loss: 0.4105 - val_accuracy: 0.8231\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8352 - val_loss: 0.4103 - val_accuracy: 0.8300\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8361 - val_loss: 0.4101 - val_accuracy: 0.8294\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8358 - val_loss: 0.4106 - val_accuracy: 0.8269\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8369 - val_loss: 0.4130 - val_accuracy: 0.8250\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8370 - val_loss: 0.4126 - val_accuracy: 0.8263\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8348 - val_loss: 0.4111 - val_accuracy: 0.8250\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8375 - val_loss: 0.4119 - val_accuracy: 0.8250\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8367 - val_loss: 0.4108 - val_accuracy: 0.8288\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8363 - val_loss: 0.4101 - val_accuracy: 0.8256\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8364 - val_loss: 0.4092 - val_accuracy: 0.8281\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8373 - val_loss: 0.4093 - val_accuracy: 0.8263\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8350 - val_loss: 0.4107 - val_accuracy: 0.8250\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8369 - val_loss: 0.4098 - val_accuracy: 0.8281\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8369 - val_loss: 0.4091 - val_accuracy: 0.8288\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8378 - val_loss: 0.4097 - val_accuracy: 0.8244\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8375 - val_loss: 0.4095 - val_accuracy: 0.8275\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8372 - val_loss: 0.4136 - val_accuracy: 0.8263\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8348 - val_loss: 0.4088 - val_accuracy: 0.8269\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8384 - val_loss: 0.4093 - val_accuracy: 0.8244\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8358 - val_loss: 0.4093 - val_accuracy: 0.8294\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8380 - val_loss: 0.4089 - val_accuracy: 0.8294\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8381 - val_loss: 0.4087 - val_accuracy: 0.8269\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8369 - val_loss: 0.4090 - val_accuracy: 0.8306\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8358 - val_loss: 0.4094 - val_accuracy: 0.8288\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8359 - val_loss: 0.4095 - val_accuracy: 0.8269\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8364 - val_loss: 0.4085 - val_accuracy: 0.8281\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8367 - val_loss: 0.4089 - val_accuracy: 0.8256\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8380 - val_loss: 0.4108 - val_accuracy: 0.8275\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8369 - val_loss: 0.4084 - val_accuracy: 0.8281\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8380 - val_loss: 0.4091 - val_accuracy: 0.8300\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8370 - val_loss: 0.4086 - val_accuracy: 0.8275\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8356 - val_loss: 0.4088 - val_accuracy: 0.8288\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8369 - val_loss: 0.4092 - val_accuracy: 0.8256\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8380 - val_loss: 0.4104 - val_accuracy: 0.8275\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8361 - val_loss: 0.4086 - val_accuracy: 0.8294\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8361 - val_loss: 0.4078 - val_accuracy: 0.8288\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8373 - val_loss: 0.4114 - val_accuracy: 0.8269\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8352 - val_loss: 0.4070 - val_accuracy: 0.8281\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8375 - val_loss: 0.4085 - val_accuracy: 0.8263\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8355 - val_loss: 0.4114 - val_accuracy: 0.8281\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8369 - val_loss: 0.4083 - val_accuracy: 0.8256\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8372 - val_loss: 0.4084 - val_accuracy: 0.8275\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8370 - val_loss: 0.4082 - val_accuracy: 0.8275\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8361 - val_loss: 0.4084 - val_accuracy: 0.8275\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8380 - val_loss: 0.4075 - val_accuracy: 0.8275\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8378 - val_loss: 0.4092 - val_accuracy: 0.8250\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8353 - val_loss: 0.4093 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8392 - val_loss: 0.4093 - val_accuracy: 0.8281\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8361 - val_loss: 0.4088 - val_accuracy: 0.8281\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8375 - val_loss: 0.4074 - val_accuracy: 0.8288\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8367 - val_loss: 0.4093 - val_accuracy: 0.8269\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8358 - val_loss: 0.4127 - val_accuracy: 0.8269\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8375 - val_loss: 0.4078 - val_accuracy: 0.8281\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8375 - val_loss: 0.4112 - val_accuracy: 0.8281\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8372 - val_loss: 0.4086 - val_accuracy: 0.8306\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8367 - val_loss: 0.4083 - val_accuracy: 0.8250\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8361 - val_loss: 0.4103 - val_accuracy: 0.8281\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8380 - val_loss: 0.4077 - val_accuracy: 0.8263\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8380 - val_loss: 0.4073 - val_accuracy: 0.8294\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8366 - val_loss: 0.4074 - val_accuracy: 0.8288\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8363 - val_loss: 0.4071 - val_accuracy: 0.8288\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8386 - val_loss: 0.4067 - val_accuracy: 0.8275\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8370 - val_loss: 0.4102 - val_accuracy: 0.8288\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8373 - val_loss: 0.4064 - val_accuracy: 0.8288\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8386 - val_loss: 0.4078 - val_accuracy: 0.8300\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8389 - val_loss: 0.4100 - val_accuracy: 0.8319\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8358 - val_loss: 0.4085 - val_accuracy: 0.8281\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8386 - val_loss: 0.4169 - val_accuracy: 0.8344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde90435390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "\n",
        "\n",
        "Use the ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d8IoCCkeWGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "85600978-d171-4dea-bd32-ed16939d7988"
      },
      "source": [
        "print(ann.predict(scaler.transform([[0.324324,0.2,600,1,40,3,60000,2,1,1,50000]])) > .5)\n",
        "# three important things to include in the predict method\n",
        "# 1. double brackets, makes 2d arryaer\n",
        "#.5 says there is more than 50% chance the customer will elave"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-680ab04a8c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.324324\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# three important things to include in the predict method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. double brackets, makes 2d arryaer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#.5 says there is more than 50% chance the customer will elave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,11) (13,) (1,11) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs"
      },
      "source": [
        "# how to change to numpy???\n",
        "\n",
        "\n",
        "y_pred = ann.predict(X_test())\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}